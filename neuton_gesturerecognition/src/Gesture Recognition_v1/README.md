Neuton, our unique neural network framework, natively creates incredibly compact and accurate models that can easily be integrated into even the smallest microcontrollers. Since our models are built compact, natively, and without compromising accuracy, there is no need to perform other functions, transformations or compression methods, such as pruning, distillation or quantization. Neuton models are ready to be embedded into a microcontroller immediately upon completion of training.  

The Neuton Platform works with tabular or sensory data, enabling you to solve problem types such as regression, time series and classification - both binomial and multinomial.

The TinyML model workflow consists of 2 stages: 

## Stage 1: Model Training

Prior to the start of training, you will need to:

-   validate that your dataset meets the minimal [standards](https://lab.neuton.ai/cb#/support_library/user_guide/TRAINING_DATASET_REQUIREMENTS) required for training. When using TinyML mode, data preprocessing and feature engineering are automatically disabled.
-   enable and configure TinyML settings within Neuton, allowing the model to be optimized for use on your specific device:

**Select bit depth of calculations**. The choice of bit depth depends on the device and the amount of free memory on it. The available options include 8, 16, and 32 bits.

**Select data normalization type**. This allows you to control the number of required resources. If the variables in the data set have different scales, the "**Unique scale for each feature**" should be selected. You may also select the "**Unified scale for all features**" if the data values ​​in the data set are approximately in the same range.

**Enable support for float calculations**. If your device supports float calculations, select this option to create models with higher accuracy. For 32 bits, the float support is enabled by default. 

During training, the Neuton Platform makes a real-time dashboard available so you can monitor the quality of the model, the number of coefficients, and the model size. Once the most optimal model quality and size is achieved training will be stopped automatically. Alternatively, you can also manually stop training once the model is deemed consistent and you have achieved your target model requirements. 

## Stage 2: Model Embedding

In order to enable predictions for your specific microcontroller and data, you must embed your resulting model and source files from the archive into your respective device. To begin the process of embedding your model into your device you'll want to take the following steps:

### Step 1: Download the model archive

The archive is available for downloading on the **Prediction** tab immediately after you stop or complete the training, and includes the following:

-   **Information about the model** - files with weight and meta-information in the two formats, binary and HEX, used in the calculation process. 2 formats are needed to support projects with and without a file system.
    -   `model/model.bin` -- The neural network model generated by Neuton in a binary format (for use from your Operating System based file system)
    -   `model/model.c` -- The neural network model generated by Neuton in a HEX format (for use directly in your device Flash memory)

-   **Calculator** - a set of functions that is an add-on to Neuton's algorithm, and provides predictions. For instance, the calculator includes functions for loading a model, calling call-back functions like transferring data, receiving calculation results, etc.
    -   `neuton/calculator.c` - Calculator wrapper functions source
    -   `neuton/calculator.h` - Calculator definitions

-   **Neuton Library** - an algorithm that performs calculations.
    -   `neuton/Neuton.c` - Neuton TinyML library source
    -   `neuton/Neuton.h` - Neuton TinyML library definitions

-   **Implementation file** - a file in which you can set the logic of actions for the results of calculations based on your business requirements.
    -   `user_app.c` - UserApp implementation of calculator callback functions.

Copy all files mentioned above from the archive into the project of your preferred IDE Tool (e.g., STM32Cube IDE).

### Step 2: Prepare the source code for the microcontroller firmware

Requirements to embed your model:

-   Code for collecting data from sensors / microphone / camera, etc. You will need to prepare this code yourself.

-   Code for processing the prediction result (for example, code for setting an alarm, sending a message or alert, etc.). You will need to prepare this code yourself.

-   The archived files downloaded from the Neuton Platform (calculator, model, and library).

-   A modified implementation file, in which a call to the data collecting code and results processing should be included. This code can be written immediately in the implementation file if it was not prepared earlier. \
You can modify the file `user_app.c`, adding code in call-back functions based on your needs. Call-back functions are described in `calculator.h`.\
\
*Some examples*:
    - To process prediction results, modify the function `CalculatorOnInferenceResult`.
    - To measure the prediction time, add code to the function `CalculatorOnInferenceStart` to start the timer and add code in the function `CalculatorOnInferenceResult` to stop the timer.

After preparation of all the components, you will also need to debug your solution prior to implementation.

Your model will be loaded into your project automatically after the calculator has initialized.

### Step 3: Download the firmware on the device

Flash memory contains the firmware code and the model, and RAM contains the data necessary for the model operation: accumulators for neurons, service information, etc.

After updating the firmware on the device, the data from the sensors will be transmitted to the calculator performing the prediction and returning the result in a fraction of a second. The prediction results are then processed according to the logic you specified while defining your application requirements.

Additional Notes: 

-   The input data for predictions must be identical in format to the data used for the training, including the order of columns. In this case, the target variable should be excluded.
-   The option to download the model is available in Neuton's Third Law (Subscription plan). However, in other plans, you can evaluate the quality of the model and its size in our web interface.